{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from nets import nets_factory\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAR_SET_LEN = 10\n",
    "#image height\n",
    "IMAGE_HEIGHT = 60\n",
    "#image width\n",
    "IMAGE_WIDTH = 160\n",
    "#batch size\n",
    "BATCH_SIZE = 32\n",
    "#tfrecord file path\n",
    "TFRECOD_FILE = \"captcha/train.tfrecords\"\n",
    "\n",
    "#placeholder\n",
    "x = tf.placeholder(tf.float32,[None,224,224])\n",
    "y0 = tf.placeholder(tf.float32,[None])\n",
    "y1 = tf.placeholder(tf.float32,[None])\n",
    "y2 = tf.placeholder(tf.float32,[None])\n",
    "y3 = tf.placeholder(tf.float32,[None])\n",
    "\n",
    "#define the learning rate\n",
    "lr = tf.Variable(0.003, dtype=tf.float32)\n",
    "\n",
    "\n",
    "def read_and_decode(filename):\n",
    "    print \"inniininininiiini\"\n",
    "    filename_queue = tf.train.string_input_producer([filename])\n",
    "    reader = tf.TFRecordReader()\n",
    "    #The read function takes the filename queue, dequeues file names and extracts the image and label\n",
    "    _,serialized_example = reader.read(filename_queue)\n",
    "    #print len(serialized_example)\n",
    "    print type(serialized_example)\n",
    "    print \"aaaaaa\"\n",
    "    features = tf.parse_single_example(serialized_example,\n",
    "                                      features={\n",
    "                                          'image':tf.FixedLenFeature([],tf.string),\n",
    "                                          'label0':tf.FixedLenFeature([],tf.int64),\n",
    "                                          'label1':tf.FixedLenFeature([],tf.int64),\n",
    "                                          'label2':tf.FixedLenFeature([],tf.int64),\n",
    "                                          'label3':tf.FixedLenFeature([],tf.int64),\n",
    "                                      })\n",
    "    # get the image data\n",
    "    image = tf.decode_raw(features['image'],tf.uint8)\n",
    "    print \"Eroor is here\"\n",
    "    image = tf.reshape(image,[224,224])\n",
    "    #image preprocessing\n",
    "    image = tf.cast(image,tf.float32) / 255.0\n",
    "    image = tf.subtract(image,0.5)\n",
    "    image = tf.multiply(image,2.0)\n",
    "    print \"test\"\n",
    "    print type(image)\n",
    "    print image.shape\n",
    "    print \"test\"\n",
    "    #get the label\n",
    "    label0 = tf.cast(features['label0'],tf.int32)\n",
    "    label1 = tf.cast(features['label1'],tf.int32)\n",
    "    label2 = tf.cast(features['label2'],tf.int32)\n",
    "    label3 = tf.cast(features['label3'],tf.int32)\n",
    "    \n",
    "    \n",
    "    return image,label0,label1,label2,label3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inniininininiiini\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "aaaaaa\n",
      "Eroor is here\n",
      "test\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(224, 224)\n",
      "test\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "Tensor(\"alexnet_v2/fc8_0/squeezed:0\", shape=(32, 10), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-3-aa86a4ddf418>:42: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n",
      "WARNING:tensorflow:From <ipython-input-3-aa86a4ddf418>:45: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n",
      "WARNING:tensorflow:From <ipython-input-3-aa86a4ddf418>:48: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n",
      "WARNING:tensorflow:From <ipython-input-3-aa86a4ddf418>:51: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n",
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, Run call was cancelled\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-aa86a4ddf418>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mb_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb_label0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb_label1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb_label2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb_label3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel1_batch0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel1_batch1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel1_batch2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel1_batch3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0mb_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mb_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mb_label0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mb_label1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mb_label2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mb_label3\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lizhibo/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lizhibo/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lizhibo/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lizhibo/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lizhibo/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# get the image and label infomation\n",
    "image,label0,label1,label2,label3 = read_and_decode(TFRECOD_FILE)\n",
    "\n",
    "\n",
    "# shuffle the input\n",
    "image_batch,label1_batch0,label1_batch1,label1_batch2,label1_batch3 = tf.train.shuffle_batch(\n",
    "    [image,label0,label1,label2,label3],batch_size = BATCH_SIZE,\n",
    "    capacity = 50000, min_after_dequeue = 10000,num_threads=1)\n",
    "print type(image_batch)\n",
    "\n",
    "\n",
    "\n",
    "# define the network structure\n",
    "train_network_fn = nets_factory.get_network_fn('alexnet_v2',\n",
    "                                              num_classes=CHAR_SET_LEN,\n",
    "                                              weight_decay=0.0005,\n",
    "                                              is_training= True)\n",
    "\n",
    "\n",
    "X = tf.reshape(x,[BATCH_SIZE,224,224,1])\n",
    "logits0,logits1,logits2,logits3,end_points = train_network_fn(X)\n",
    "print logits0\n",
    "\n",
    "# convert the label to one_hot\n",
    "one_hot_labels0 = tf.one_hot(indices=tf.cast(y0,tf.int32),depth=CHAR_SET_LEN)\n",
    "one_hot_labels1 = tf.one_hot(indices=tf.cast(y1,tf.int32),depth=CHAR_SET_LEN)\n",
    "one_hot_labels2 = tf.one_hot(indices=tf.cast(y2,tf.int32),depth=CHAR_SET_LEN)\n",
    "one_hot_labels3 = tf.one_hot(indices=tf.cast(y3,tf.int32),depth=CHAR_SET_LEN)\n",
    "\n",
    "# calculate loss\n",
    "loss0 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits0,labels=one_hot_labels0))\n",
    "loss1 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits1,labels=one_hot_labels1))\n",
    "loss2 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits2,labels=one_hot_labels2))\n",
    "loss3 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits3,labels=one_hot_labels3))\n",
    "\n",
    "# calculate the total loss\n",
    "total_loss = (loss0 + loss1 + loss2 + loss3) / 4.0\n",
    "#optimize the total loss\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(total_loss)\n",
    "\n",
    "# calculate the accuracy \n",
    "correct_prediction0 = tf.equal(tf.argmax(one_hot_labels0,1),tf.arg_max(logits0,1))\n",
    "accuracy0 = tf.reduce_mean(tf.cast(correct_prediction0,tf.float32))\n",
    "\n",
    "correct_prediction1 = tf.equal(tf.argmax(one_hot_labels1,1),tf.arg_max(logits1,1))\n",
    "accuracy1 = tf.reduce_mean(tf.cast(correct_prediction1,tf.float32))\n",
    "\n",
    "correct_prediction2 = tf.equal(tf.argmax(one_hot_labels2,1),tf.arg_max(logits2,1))\n",
    "accuracy2 = tf.reduce_mean(tf.cast(correct_prediction2,tf.float32))\n",
    "\n",
    "correct_prediction3 = tf.equal(tf.argmax(one_hot_labels3,1),tf.arg_max(logits3,1))\n",
    "accuracy3 = tf.reduce_mean(tf.cast(correct_prediction3,tf.float32))\n",
    "\n",
    "# save the model\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "   \n",
    "    #initialzation\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess,coord=coord)\n",
    "    \n",
    "    for i in range(6001):\n",
    "        b_image,b_label0,b_label1,b_label2,b_label3 = sess.run([image_batch,label1_batch0,label1_batch1,label1_batch2,label1_batch3])\n",
    "        print b_image.shape\n",
    "        sess.run(optimizer, feed_dict={x: b_image, y0:b_label0, y1: b_label1, y2 : b_label2, y3:b_label3})\n",
    "        \n",
    "        if i % 20 == 0:\n",
    "            if i % 2000 == 0:\n",
    "                sess.run(tf.assign(lr,lr/3))\n",
    "            acc0,acc1,acc2,acc3,loss_=sess.run([accuracy0,accuracy1,accuracy2,accuracy3,total_loss],feed_dict={x: b_image,\n",
    "                                                                                                             y0: b_label0,\n",
    "                                                                                                             y1: b_label1,\n",
    "                                                                                                             y2: b_label2,\n",
    "                                                                                                             y3: b_label3})\n",
    "            learning_rate = sess.run(lr)\n",
    "            print(\"Iter:%d Loss:%.3f Accuracy:%.2f,%.2f,%.2f%.2f Learning_rate:%.4f\" % (i,loss_,acc0,acc1,acc2,acc3,learning_rate))\n",
    "            \n",
    "            if i == 6000:\n",
    "                saver.save(sees,\"captcha/models/crack_captcha.model\",global_step=i)\n",
    "                break\n",
    "    \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
